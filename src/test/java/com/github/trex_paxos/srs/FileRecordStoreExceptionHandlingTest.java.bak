package com.github.trex_paxos.srs;

import org.junit.After;
import org.junit.Assert;
import org.junit.Before;
import org.junit.Test;

import java.io.IOException;
import java.io.RandomAccessFile;
import java.nio.charset.StandardCharsets;
import java.nio.file.Files;
import java.nio.file.Path;
import java.util.HashMap;
import java.util.Map;
import java.util.Set;
import java.util.logging.Level;
import java.util.logging.Logger;

/// Comprehensive test for FileRecordStore closed state behavior after exceptions.
/// This test uses proper resource management and controlled exception injection
/// to verify that the store correctly handles exceptions and prevents reuse.
public class FileRecordStoreExceptionHandlingTest extends JulLoggingConfig {
    
    private static final Logger logger = Logger.getLogger(FileRecordStoreExceptionHandlingTest.class.getName());
    
    /// Discover the total operation count for a simple insert without exception injection
    private int discoverOperationCount() throws Exception {
        logger.log(Level.FINE, "=== Discovering total operation count for simple insert ===");
        
        // Create store with counting wrapper that never throws (use Integer.MAX_VALUE)
        FileRecordStore.Builder builder = new FileRecordStore.Builder()
            .tempFile("discovery-", ".db");
        
        // Create the store normally first
        FileRecordStore baseStore = builder.open();
        
        // Replace file operations with counting wrapper that never throws
        RandomAccessFile raf = new RandomAccessFile(baseStore.getFilePath().toFile(), "rw");
        DirectRandomAccessFile directOps = new DirectRandomAccessFile(raf);
        DelegatingExceptionOperations countingOps = new DelegatingExceptionOperations(directOps, Integer.MAX_VALUE);
        
        // Create new store with counting wrapper  
        FileRecordStore countingStore = builder.path(baseStore.getFilePath()).open();
        countingStore.fileOperations = countingOps;
        
        // Close the base store since we're done with it
        baseStore.close();
        
        // Perform simple insert
        ByteSequence key = ByteSequence.of("testkey".getBytes());
        byte[] data = "testdata".getBytes();
        
        try {
            countingStore.insertRecord(key, data);
        } catch (IOException e) {
            // Should not happen with Integer.MAX_VALUE
            logger.log(Level.FINE, "Unexpected exception during operation count discovery", e);
        }
        
        // Get the operation count from the delegating operations
        int totalOps = ((DelegatingExceptionOperations) countingStore.fileOperations).getOperationCount();
        
        countingStore.close();
        
        logger.log(Level.FINE, () -> String.format("Discovered %d operations for simple insert", totalOps));
        return totalOps;
    }
    
    /// Discover total operation count for delete
    private int discoverDeleteOperationCount() throws Exception {
        logger.log(Level.FINE, "=== Discovering total operation count for delete ===");
        
        FileRecordStore.Builder builder = new FileRecordStore.Builder()
            .tempFile("delete-discovery-", ".db");
        
        // Create base store
        FileRecordStore baseStore = builder.open();
        
        // Replace with counting delegate that never throws
        RandomAccessFile raf = new RandomAccessFile(baseStore.getFilePath().toFile(), "rw");
        DirectRandomAccessFile directOps = new DirectRandomAccessFile(raf);
        DelegatingExceptionOperations countingOps = new DelegatingExceptionOperations(directOps, Integer.MAX_VALUE);
        
        // Create store with counting wrapper
        FileRecordStore countingStore = builder.path(baseStore.getFilePath()).open();
        countingStore.fileOperations = countingOps;
        
        baseStore.close();
        
        // Setup: insert a record first
        ByteSequence key = ByteSequence.of("testkey".getBytes());
        byte[] data = "testdata".getBytes();
        countingStore.insertRecord(key, data);
        
        // Reset counter before delete
        countingOps.getOperationCount(); // This resets the count
        
        // Perform delete
        countingStore.deleteRecord(key);
        
        // Get the operation count from the delegating operations
        int totalOps = ((DelegatingExceptionOperations) countingStore.fileOperations).getOperationCount();
        
        countingStore.close();
        
        logger.log(Level.FINE, () -> String.format("Discovered %d operations for simple delete", totalOps));
        return totalOps;
    }
    
    /// Discover total operation count for insert scenario (with free space)
    private int discoverInsertScenarioOperationCount() throws Exception {
        logger.log(Level.FINE, "=== Discovering total operation count for insert scenario ===");
        
        FileRecordStore.Builder builder = new FileRecordStore.Builder()
            .tempFile("insert-scenario-discovery-", ".db");
        
        // Create base store
        FileRecordStore baseStore = builder.open();
        
        // Replace with counting delegate that never throws
        RandomAccessFile raf = new RandomAccessFile(baseStore.getFilePath().toFile(), "rw");
        DirectRandomAccessFile directOps = new DirectRandomAccessFile(raf);
        DelegatingExceptionOperations countingOps = new DelegatingExceptionOperations(directOps, Integer.MAX_VALUE);
        
        // Create store with counting wrapper
        FileRecordStore countingStore = builder.path(baseStore.getFilePath()).open();
        countingStore.fileOperations = countingOps;
        
        baseStore.close();
        
        // Setup: create free space scenario (insert records, delete some, then insert new one)
        ByteSequence key1 = ByteSequence.of("existing0".getBytes());
        ByteSequence key2 = ByteSequence.of("existing1".getBytes());
        ByteSequence key3 = ByteSequence.of("existing2".getBytes());
        ByteSequence key4 = ByteSequence.of("existing3".getBytes());
        ByteSequence key5 = ByteSequence.of("existing4".getBytes());
        byte[] data = "testdata".getBytes();
        
        countingStore.insertRecord(key1, data);
        countingStore.insertRecord(key2, data);
        countingStore.insertRecord(key3, data);
        countingStore.insertRecord(key4, data);
        countingStore.insertRecord(key5, data);
        
        // Delete some to create free space
        countingStore.deleteRecord(key2);
        countingStore.deleteRecord(key4);
        
        // Reset counter before insert
        countingOps.getOperationCount(); // This resets the count
        
        // Perform insert into free space
        ByteSequence newKey = ByteSequence.of("newkey".getBytes());
        countingStore.insertRecord(newKey, data);
        
        // Get the operation count from the delegating operations
        int totalOps = ((DelegatingExceptionOperations) countingStore.fileOperations).getOperationCount();
        
        countingStore.close();
        
        logger.log(Level.FINE, () -> String.format("Discovered %d operations for insert scenario", totalOps));
        return totalOps;
    }
    
    /// Discover total operation count for update scenario
    private int discoverUpdateScenarioOperationCount() throws Exception {
        logger.log(Level.FINE, "=== Discovering total operation count for update scenario ===");
        
        FileRecordStore.Builder builder = new FileRecordStore.Builder()
            .tempFile("update-scenario-discovery-", ".db");
        
        // Create base store
        FileRecordStore baseStore = builder.open();
        
        // Replace with counting delegate that never throws
        RandomAccessFile raf = new RandomAccessFile(baseStore.getFilePath().toFile(), "rw");
        DirectRandomAccessFile directOps = new DirectRandomAccessFile(raf);
        DelegatingExceptionOperations countingOps = new DelegatingExceptionOperations(directOps, Integer.MAX_VALUE);
        
        // Create store with counting wrapper
        FileRecordStore countingStore = builder.path(baseStore.getFilePath()).open();
        countingStore.fileOperations = countingOps;
        
        baseStore.close();
        
        // Setup: insert record, then update it (same size)
        ByteSequence key = ByteSequence.of("updatekey".getBytes());
        byte[] initialData = "initialdata".getBytes();
        byte[] updatedData = "updateddata".getBytes(); // Same length
        
        countingStore.insertRecord(key, initialData);
        
        // Reset counter before update
        countingOps.getOperationCount(); // This resets the count
        
        // Perform update (same size)
        countingStore.updateRecord(key, updatedData);
        
        // Get the operation count from the delegating operations
        int totalOps = ((DelegatingExceptionOperations) countingStore.fileOperations).getOperationCount();
        
        countingStore.close();
        
        logger.log(Level.FINE, () -> String.format("Discovered %d operations for update scenario", totalOps));
        return totalOps;
    }
    
    /// Discover total operation count for read scenario
    private int discoverReadScenarioOperationCount() throws Exception {
        logger.log(Level.FINE, "=== Discovering total operation count for read scenario ===");
        
        FileRecordStore.Builder builder = new FileRecordStore.Builder()
            .tempFile("read-scenario-discovery-", ".db");
        
        // Create base store
        FileRecordStore baseStore = builder.open();
        
        // Replace with counting delegate that never throws
        RandomAccessFile raf = new RandomAccessFile(baseStore.getFilePath().toFile(), "rw");
        DirectRandomAccessFile directOps = new DirectRandomAccessFile(raf);
        DelegatingExceptionOperations countingOps = new DelegatingExceptionOperations(directOps, Integer.MAX_VALUE);
        
        // Create store with counting wrapper
        FileRecordStore countingStore = builder.path(baseStore.getFilePath()).open();
        countingStore.fileOperations = countingOps;
        
        baseStore.close();
        
        // Setup: insert record, then read it
        ByteSequence key = ByteSequence.of("readkey".getBytes());
        byte[] data = "readdata".getBytes();
        
        countingStore.insertRecord(key, data);
        
        // Reset counter before read
        countingOps.getOperationCount(); // This resets the count
        
        // Perform read
        byte[] readData = countingStore.readRecordData(key);
        
        // Verify data
        Assert.assertArrayEquals(data, readData);
        
        // Get the operation count from the delegating operations
        int totalOps = ((DelegatingExceptionOperations) countingStore.fileOperations).getOperationCount();
        
        countingStore.close();
        
        logger.log(Level.FINE, () -> String.format("Discovered %d operations for read scenario", totalOps));
        return totalOps;
    }
    
    /// Discover total operation count for max key length scenario
    private int discoverMaxKeyLengthScenarioOperationCount() throws Exception {
        logger.log(Level.FINE, "=== Discovering total operation count for max key length scenario ===");
        
        FileRecordStore.Builder builder = new FileRecordStore.Builder()
            .tempFile("maxkey-scenario-discovery-", ".db")
            .maxKeyLength(248); // Max theoretical key length
        
        // Create base store
        FileRecordStore baseStore = builder.open();
        
        // Replace with counting delegate that never throws
        RandomAccessFile raf = new RandomAccessFile(baseStore.getFilePath().toFile(), "rw");
        DirectRandomAccessFile directOps = new DirectRandomAccessFile(raf);
        DelegatingExceptionOperations countingOps = new DelegatingExceptionOperations(directOps, Integer.MAX_VALUE);
        
        // Create store with counting wrapper
        FileRecordStore countingStore = builder.path(baseStore.getFilePath()).open();
        countingStore.fileOperations = countingOps;
        
        baseStore.close();
        
        // Setup: create max length key
        byte[] maxKeyBytes = new byte[248];
        for (int i = 0; i < 248; i++) {
            maxKeyBytes[i] = (byte) (i % 256);
        }
        ByteSequence maxKey = ByteSequence.of(maxKeyBytes);
        byte[] data = "maxkeydata".getBytes();
        
        // Reset counter before insert
        countingOps.getOperationCount(); // This resets the count
        
        // Perform insert with max key length
        countingStore.insertRecord(maxKey, data);
        
        // Get the operation count from the delegating operations
        int totalOps = ((DelegatingExceptionOperations) countingStore.fileOperations).getOperationCount();
        
        countingStore.close();
        
        logger.log(Level.FINE, () -> String.format("Discovered %d operations for max key length scenario", totalOps));
        return totalOps;
    }
    
    /// Discover total operation count for empty data scenario
    private int discoverEmptyDataScenarioOperationCount() throws Exception {
        logger.log(Level.FINE, "=== Discovering total operation count for empty data scenario ===");
        
        FileRecordStore.Builder builder = new FileRecordStore.Builder()
            .tempFile("emptydata-scenario-discovery-", ".db");
        
        // Create base store
        FileRecordStore baseStore = builder.open();
        
        // Replace with counting delegate that never throws
        RandomAccessFile raf = new RandomAccessFile(baseStore.getFilePath().toFile(), "rw");
        DirectRandomAccessFile directOps = new DirectRandomAccessFile(raf);
        DelegatingExceptionOperations countingOps = new DelegatingExceptionOperations(directOps, Integer.MAX_VALUE);
        
        // Create store with counting wrapper
        FileRecordStore countingStore = builder.path(baseStore.getFilePath()).open();
        countingStore.fileOperations = countingOps;
        
        baseStore.close();
        
        // Setup: insert record with empty data
        ByteSequence key = ByteSequence.of("emptykey".getBytes());
        byte[] emptyData = new byte[0];
        
        // Reset counter before insert
        countingOps.getOperationCount(); // This resets the count
        
        // Perform insert with empty data
        countingStore.insertRecord(key, emptyData);
        
        // Get the operation count from the delegating operations
        int totalOps = ((DelegatingExceptionOperations) countingStore.fileOperations).getOperationCount();
        
        countingStore.close();
        
        logger.log(Level.FINE, () -> String.format("Discovered %d operations for empty data scenario", totalOps));
        return totalOps;
    }
    
    /// Discover total operation count for fsync scenario
    private int discoverFsyncScenarioOperationCount() throws Exception {
        logger.log(Level.FINE, "=== Discovering total operation count for fsync scenario ===");
        
        FileRecordStore.Builder builder = new FileRecordStore.Builder()
            .tempFile("fsync-scenario-discovery-", ".db");
        
        // Create base store
        FileRecordStore baseStore = builder.open();
        
        // Replace with counting delegate that never throws
        RandomAccessFile raf = new RandomAccessFile(baseStore.getFilePath().toFile(), "rw");
        DirectRandomAccessFile directOps = new DirectRandomAccessFile(raf);
        DelegatingExceptionOperations countingOps = new DelegatingExceptionOperations(directOps, Integer.MAX_VALUE);
        
        // Create store with counting wrapper
        FileRecordStore countingStore = builder.path(baseStore.getFilePath()).open();
        countingStore.fileOperations = countingOps;
        
        baseStore.close();
        
        // Setup: add some data to ensure there are file operations
        ByteSequence key = ByteSequence.of("fsynckey".getBytes());
        byte[] data = "fsyncdata".getBytes();
        
        countingStore.insertRecord(key, data);
        
        // Reset counter before fsync
        countingOps.getOperationCount(); // This resets the count
        
        // Perform fsync - this should trigger sync operations
        countingStore.fsync();
        
        // Get the operation count from the delegating operations
        int totalOps = ((DelegatingExceptionOperations) countingStore.fileOperations).getOperationCount();
        
        countingStore.close();
        
        logger.log(Level.FINE, () -> String.format("Discovered %d operations for fsync scenario", totalOps));
        
        // If fsync doesn't trigger any operations, return 0 so we skip testing
        return totalOps;
    }
    
    /// Discover total operation count for file growth scenario
    private int discoverFileGrowthScenarioOperationCount() throws Exception {
        logger.log(Level.FINE, "=== Discovering total operation count for file growth scenario ===");
        
        FileRecordStore.Builder builder = new FileRecordStore.Builder()
            .tempFile("filegrowth-scenario-discovery-", ".db");
        
        // Create base store
        FileRecordStore baseStore = builder.open();
        
        // Replace with counting delegate that never throws
        RandomAccessFile raf = new RandomAccessFile(baseStore.getFilePath().toFile(), "rw");
        DirectRandomAccessFile directOps = new DirectRandomAccessFile(raf);
        DelegatingExceptionOperations countingOps = new DelegatingExceptionOperations(directOps, Integer.MAX_VALUE);
        
        // Create store with counting wrapper
        FileRecordStore countingStore = builder.path(baseStore.getFilePath()).open();
        countingStore.fileOperations = countingOps;
        
        baseStore.close();
        
        // Setup: insert large record to force file growth
        ByteSequence key = ByteSequence.of("largekey".getBytes());
        byte[] largeData = new byte[1024]; // 1KB should force growth
        
        countingStore.insertRecord(key, largeData);
        
        // Reset counter before another insert that should cause growth
        countingOps.getOperationCount(); // This resets the count
        
        // Perform another insert that should cause file growth
        ByteSequence key2 = ByteSequence.of("anotherkey".getBytes());
        byte[] moreLargeData = new byte[2048]; // 2KB
        countingStore.insertRecord(key2, moreLargeData);
        
        // Get the operation count from the delegating operations
        int totalOps = ((DelegatingExceptionOperations) countingStore.fileOperations).getOperationCount();
        
        countingStore.close();
        
        logger.log(Level.FINE, () -> String.format("Discovered %d operations for file growth scenario", totalOps));
        return totalOps;
    }
    
    /// Discover total operation count for index manipulation scenario
    private int discoverIndexManipulationScenarioOperationCount(Path filePath) throws Exception {
        logger.log(Level.FINE, "=== Discovering total operation count for index manipulation scenario ===");
        
        // Create store with the specified path (pre-populated)
        FileRecordStore countingStore = new FileRecordStore.Builder()
            .path(filePath)
            .open();
        
        // Replace with counting delegate that never throws
        RandomAccessFile raf = new RandomAccessFile(countingStore.getFilePath().toFile(), "rw");
        DirectRandomAccessFile directOps = new DirectRandomAccessFile(raf);
        DelegatingExceptionOperations countingOps = new DelegatingExceptionOperations(directOps, Integer.MAX_VALUE);
        
        // Replace file operations with counting wrapper
        countingStore.fileOperations = countingOps;
        
        // Reset counter before insert
        countingOps.getOperationCount(); // This resets the count
        
        // Perform insert into existing store (this will manipulate indexes)
        ByteSequence newKey = ByteSequence.of("newkey".getBytes());
        byte[] data = "newdata".getBytes();
        countingStore.insertRecord(newKey, data);
        
        // Get the operation count from the delegating operations
        int totalOps = ((DelegatingExceptionOperations) countingStore.fileOperations).getOperationCount();
        
        countingStore.close();
        
        logger.log(Level.FINE, () -> String.format("Discovered %d operations for index manipulation scenario", totalOps));
        return totalOps;
    }
    
    /// Test that exceptions trigger closed state and subsequent operations fail
    @Test
    public void testExceptionClosesStoreAndPreventsReuse() throws Exception {
        logger.log(Level.FINE, "=== Testing exception closes store and prevents reuse - RECORD AND PLAYBACK ===");
        
        // RECORD PHASE: Discover total operation count for simple insert
        int totalOperations = discoverOperationCount();
        logger.log(Level.FINE, () -> String.format("Discovered total operations for simple insert: %d", totalOperations));
        
        // PLAYBACK PHASE: Test exceptions at each operation from 1 to totalOperations
        for (int throwAt = 1; throwAt <= totalOperations; throwAt++) {
            final int finalThrowAt = throwAt; // Make it effectively final for lambda
            logger.log(Level.FINE, () -> String.format("RECORD AND PLAYBACK: Testing exception at operation %d/%d", finalThrowAt, totalOperations));
            
            // Create store with exception injection
            FileRecordStore store = null;
            boolean storeCreated = false;
            
            try {
                store = createStoreWithException(finalThrowAt);
                storeCreated = true; // Store was successfully created
            } catch (IOException e) {
                logger.log(Level.FINE, () -> String.format("RECORD AND PLAYBACK: Exception during store creation at operation %d: %s", finalThrowAt, e.getMessage()));
                // Store failed to construct - this is expected for early operations
                // No need to test further as store was never properly opened
                continue;
            }
            
            if (storeCreated) {
                ByteSequence key = ByteSequence.of("testkey".getBytes());
                byte[] data = "testdata".getBytes();
                
                try {
                    // This should trigger an exception at the specified operation
                    store.insertRecord(key, data);
                    // If we get here without exception, that's fine - some operations might not be reached
                    logger.log(Level.FINE, () -> String.format("Operation %d not reached - that's expected", finalThrowAt));
                } catch (IOException e) {
                    logger.log(Level.FINE, () -> String.format("RECORD AND PLAYBACK: Got expected exception at operation %d: %s", finalThrowAt, e.getMessage()));
                    // Store should now be closed (only if it was successfully created first)
                    Assert.assertTrue("RECORD AND PLAYBACK: Store should be closed after exception at operation " + finalThrowAt, store.isClosed());
                    
                    // All subsequent operations should throw IllegalStateException
                    verifyStoreIsClosed(store);
                }
                
                // Close the store (whether it failed or not)
                try {
                    store.close();
                } catch (Exception e) {
                    // Ignore close exceptions
                }
            }
        }
        
        logger.log(Level.FINE, "=== RECORD AND PLAYBACK: Completed testing all operations 1-" + totalOperations + " ===");
    }
    
    /// Test that recovery requires creating a new FileRecordStore instance
    @Test
    public void testRecoveryRequiresNewFileRecordStore() throws Exception {
        logger.log(Level.FINE, "=== Testing recovery requires new FileRecordStore instance ===");
        
        // Create first store with exception injection
        FileRecordStore corruptedStore = createStoreWithException(5);
        ByteSequence key = ByteSequence.of("testkey".getBytes());
        byte[] data = "testdata".getBytes();
        
        // Trigger exception to corrupt the store
        try {
            corruptedStore.insertRecord(key, data);
            Assert.fail("Expected IOException");
        } catch (IOException e) {
            // Expected - store is now corrupted
        }
        
        Assert.assertTrue("Corrupted store should be closed", corruptedStore.isClosed());
        
        // Close the corrupted store
        corruptedStore.close();
        
        // Create a completely new FileRecordStore for the same file
        FileRecordStore newStore = new FileRecordStore.Builder()
            .tempFile("recovery-test-", ".db")
            .open();
        
        // New store should work fine
        Assert.assertFalse("New store should not be closed", newStore.isClosed());
        
        ByteSequence newKey = ByteSequence.of("newkey".getBytes());
        byte[] newData = "newdata".getBytes();
        
        newStore.insertRecord(newKey, newData);
        byte[] readData = newStore.readRecordData(newKey);
        Assert.assertArrayEquals("Data should be readable from new store", newData, readData);
        
        newStore.close();
    }
    
    /// Test all public methods throw IllegalStateException after closed
    @Test
    public void testAllMethodsThrowIllegalStateExceptionAfterClosed() throws Exception {
        logger.log(Level.FINE, "=== Testing all methods throw IllegalStateException after closed ===");
        
        // Create store and trigger exception to close it
        FileRecordStore store = createStoreWithException(3);
        ByteSequence key = ByteSequence.of("testkey".getBytes());
        byte[] data = "testdata".getBytes();
        
        try {
            store.insertRecord(key, data);
            Assert.fail("Expected IOException");
        } catch (IOException e) {
            // Expected - store should be closed
        }
        
        Assert.assertTrue("Store should be closed", store.isClosed());
        
        // Test all public methods throw IllegalStateException
        verifyStoreIsClosed(store);
    }
    
    /// Test that successful operations don't close the store
    @Test
    public void testSuccessfulOperationsDoNotCloseStore() throws Exception {
        logger.log(Level.FINE, "=== Testing successful operations do not close store ===");
        
        // Create normal store without exception injection
        FileRecordStore store = new FileRecordStore.Builder()
            .tempFile("success-test-", ".db")
            .open();
        
        ByteSequence key = ByteSequence.of("testkey".getBytes());
        byte[] data = "testdata".getBytes();
        
        // Perform successful operations
        store.insertRecord(key, data);
        Assert.assertFalse("Store should not be closed after successful insert", store.isClosed());
        
        byte[] readData = store.readRecordData(key);
        Assert.assertArrayEquals("Data should match", data, readData);
        Assert.assertFalse("Store should not be closed after successful read", store.isClosed());
        
        store.updateRecord(key, "updated".getBytes());
        Assert.assertFalse("Store should not be closed after successful update", store.isClosed());
        
        store.deleteRecord(key);
        Assert.assertFalse("Store should not be closed after successful delete", store.isClosed());
        
        Assert.assertTrue("Store should not be empty initially", store.isEmpty());
        Assert.assertFalse("Store should not be closed after isEmpty", store.isClosed());
        
        // Test keys() method
        store.insertRecord(key, data);
        Iterable<ByteSequence> keys = store.keys();
        Assert.assertFalse("Store should not be closed after keys()", store.isClosed());
        
        // Test recordExists() method
        Assert.assertTrue("Record should exist", store.recordExists(key));
        Assert.assertFalse("Store should not be closed after recordExists()", store.isClosed());
        
        store.close();
    }

    /// Test file header operations failure scenarios using record-and-playback
    @Test
    public void testFileHeaderOperationsFailure() throws Exception {
        logger.log(Level.FINE, "=== Testing file header operations failure (record-and-playback) ===");
        
        // Discover total operations for simple insert
        int totalOperations = discoverOperationCount();
        logger.log(Level.FINE, () -> String.format("Discovered %d operations for simple insert", totalOperations));
        
        // Test early operations that would affect file headers (first few operations)
        int[] headerOperations = {1, 2, 3, 4, 5, 6};
        
        for (int throwAt : headerOperations) {
            if (throwAt <= totalOperations) {
                logger.log(Level.FINE, () -> String.format("Testing header operation failure at operation %d", throwAt));
                testExceptionScenarioWithBehaviorVerification(throwAt, "header operation " + throwAt);
            }
        }
    }

    /// Test index manipulation operations failure using dynamic discovery
    @Test
    public void testIndexManipulationFailure() throws Exception {
        logger.log(Level.FINE, "=== Testing index manipulation operations failure with dynamic discovery ===");
        
        // Pre-populate store to test index operations
        FileRecordStore prepStore = new FileRecordStore.Builder()
            .tempFile("index-prep-", ".db")
            .open();
        
        ByteSequence key1 = ByteSequence.of("key1".getBytes());
        ByteSequence key2 = ByteSequence.of("key2".getBytes());
        prepStore.insertRecord(key1, "data1".getBytes());
        prepStore.insertRecord(key2, "data2".getBytes());
        Path filePath = prepStore.getFilePath();
        prepStore.close();
        
        // Discover total operation count for insert into existing store
        int totalOps = discoverIndexManipulationScenarioOperationCount(filePath);
        logger.log(Level.FINE, () -> String.format("Discovered %d operations for index manipulation scenario", totalOps));
        
        // Test a few representative operations
        int[] testOperations = {1, Math.min(3, totalOps), Math.min(5, totalOps)};
        
        for (int op : testOperations) {
            if (op <= totalOps) {
                logger.log(Level.FINE, () -> String.format("Testing index manipulation at operation %d/%d", op, totalOps));
                testExceptionScenarioAtPath(filePath, op, "index manipulation operation " + op);
            }
        }
    }

    /// Test data write operations failure using dynamic discovery
    @Test
    public void testDataWriteOperationsFailure() throws Exception {
        logger.log(Level.FINE, "=== Testing data write operations failure with dynamic discovery ===");
        
        // Discover total operation count for simple insert (which includes data write operations)
        int totalOps = discoverOperationCount();
        logger.log(Level.FINE, () -> String.format("Discovered %d total operations for simple insert", totalOps));
        
        // Test a few representative operations that would include data write operations
        int[] testOperations = {1, Math.min(3, totalOps), Math.min(5, totalOps)};
        
        for (int op : testOperations) {
            if (op <= totalOps) {
                logger.log(Level.FINE, () -> String.format("Testing data write operations at operation %d/%d", op, totalOps));
                testExceptionScenario(op, "data write operation " + op);
            }
        }
    }

    /// Test file growth operations using dynamic discovery
    @Test
    public void testFileGrowthOperationsFailure() throws Exception {
        logger.log(Level.FINE, "=== Testing file growth operations failure with dynamic discovery ===");
        
        // Discover total operation count for scenario that causes file growth
        int totalOps = discoverFileGrowthScenarioOperationCount();
        logger.log(Level.FINE, () -> String.format("Discovered %d operations for file growth scenario", totalOps));
        
        // Test a few representative operations
        int[] testOperations = {1, Math.min(3, totalOps), Math.min(5, totalOps)};
        
        for (int op : testOperations) {
            if (op <= totalOps) {
                logger.log(Level.FINE, () -> String.format("Testing file growth operations at operation %d/%d", op, totalOps));
                testExceptionScenario(op, "file growth operation " + op);
            }
        }
    }

    /// Test specific insert scenarios using dynamic operation discovery
    @Test
    public void testInsertScenarios() throws Exception {
        logger.log(Level.FINE, "=== Testing specific insert scenarios with dynamic discovery ===");
        
        // Discover total operation count for insert into free space scenario
        int totalInsertOps = discoverInsertScenarioOperationCount();
        logger.log(Level.FINE, () -> String.format("Discovered %d operations for insert scenario", totalInsertOps));
        
        // Test a few representative operations
        int[] testOperations = {1, Math.min(3, totalInsertOps), Math.min(5, totalInsertOps)};
        
        for (int op : testOperations) {
            if (op <= totalInsertOps) {
                logger.log(Level.FINE, () -> String.format("Testing insert scenario at operation %d/%d", op, totalInsertOps));
                testInsertScenarioWithException(op, "insert scenario operation " + op);
            }
        }
    }

    /// Test specific update scenarios using dynamic operation discovery
    @Test
    public void testUpdateScenarios() throws Exception {
        logger.log(Level.FINE, "=== Testing specific update scenarios with dynamic discovery ===");
        
        // Discover total operation count for update scenario
        int totalUpdateOps = discoverUpdateScenarioOperationCount();
        logger.log(Level.FINE, () -> String.format("Discovered %d operations for update scenario", totalUpdateOps));
        
        // Test a few representative operations
        int[] testOperations = {1, Math.min(3, totalUpdateOps), Math.min(5, totalUpdateOps)};
        
        for (int op : testOperations) {
            if (op <= totalUpdateOps) {
                logger.log(Level.FINE, () -> String.format("Testing update scenario at operation %d/%d", op, totalUpdateOps));
                testUpdateScenarioWithException(op, "update scenario operation " + op);
            }
        }
    }

    /// Test specific delete scenarios using dynamic operation discovery
    @Test
    public void testDeleteScenarios() throws Exception {
        logger.log(Level.FINE, "=== Testing specific delete scenarios with dynamic discovery ===");
        
        // Discover total operation count for delete
        int totalDeleteOps = discoverDeleteOperationCount();
        logger.log(Level.FINE, () -> String.format("Discovered %d operations for simple delete", totalDeleteOps));
        
        // Test a few representative operations - only test operations that are actually reached
        int[] testOperations = {1, Math.min(2, totalDeleteOps), Math.min(3, totalDeleteOps)};
        
        for (int op : testOperations) {
            if (op <= totalDeleteOps) {
                logger.log(Level.FINE, () -> String.format("Testing delete scenario at operation %d/%d", op, totalDeleteOps));
                testDeleteScenarioWithException(op, "delete operation " + op);
            }
        }
    }

    /// Test specific read scenarios using dynamic operation discovery
    @Test
    public void testReadScenarios() throws Exception {
        logger.log(Level.FINE, "=== Testing specific read scenarios with dynamic discovery ===");
        
        // Discover total operation count for read scenario
        int totalReadOps = discoverReadScenarioOperationCount();
        logger.log(Level.FINE, () -> String.format("Discovered %d operations for read scenario", totalReadOps));
        
        // Test a few representative operations
        int[] testOperations = {1, Math.min(2, totalReadOps), Math.min(3, totalReadOps)};
        
        for (int op : testOperations) {
            if (op <= totalReadOps) {
                logger.log(Level.FINE, () -> String.format("Testing read scenario at operation %d/%d", op, totalReadOps));
                testReadScenarioWithException(op, "read scenario operation " + op, false);
            }
        }
    }

    /// Test edge cases and boundary conditions using dynamic discovery
    @Test
    public void testEdgeCasesAndBoundaries() throws Exception {
        logger.log(Level.FINE, "=== Testing edge cases and boundary conditions with dynamic discovery ===");
        
        // Test max key length scenario
        int totalMaxKeyOps = discoverMaxKeyLengthScenarioOperationCount();
        logger.log(Level.FINE, () -> String.format("Discovered %d operations for max key length scenario", totalMaxKeyOps));
        
        // Test a few representative operations
        int[] testOperations = {1, Math.min(2, totalMaxKeyOps), Math.min(3, totalMaxKeyOps)};
        
        for (int op : testOperations) {
            if (op <= totalMaxKeyOps) {
                logger.log(Level.FINE, () -> String.format("Testing max key length scenario at operation %d/%d", op, totalMaxKeyOps));
                testMaxKeyLengthScenario(op);
            }
        }
        
        // Test empty data scenario
        int totalEmptyDataOps = discoverEmptyDataScenarioOperationCount();
        logger.log(Level.FINE, () -> String.format("Discovered %d operations for empty data scenario", totalEmptyDataOps));
        
        for (int op : testOperations) {
            if (op <= totalEmptyDataOps) {
                logger.log(Level.FINE, () -> String.format("Testing empty data scenario at operation %d/%d", op, totalEmptyDataOps));
                testEmptyDataScenario(op);
            }
        }
        
        // Test fsync scenario
        int totalFsyncOps = discoverFsyncScenarioOperationCount();
        logger.log(Level.FINE, () -> String.format("Discovered %d operations for fsync scenario", totalFsyncOps));
        
        // Only test fsync if it actually triggers operations
        if (totalFsyncOps > 0) {
            int[] fsyncTestOperations = {1, Math.min(2, totalFsyncOps), Math.min(3, totalFsyncOps)};
            for (int op : fsyncTestOperations) {
                if (op <= totalFsyncOps && op > 0) {
                    logger.log(Level.FINE, () -> String.format("Testing fsync scenario at operation %d/%d", op, totalFsyncOps));
                    testFsyncScenarioWithException(op, "fsync scenario operation " + op);
                }
            }
        } else {
            logger.log(Level.FINE, "Fsync scenario doesn't trigger any file operations - skipping fsync tests");
        }
    }

    /// Helper method for exception scenario testing
    private void testExceptionScenario(int throwAt, String description) throws Exception {
        testExceptionScenarioAtPath(null, throwAt, description);
    }

    /// Helper method for exception scenario testing at specific path
    private void testExceptionScenarioAtPath(Path filePath, int throwAt, String description) throws Exception {
        logger.log(Level.FINE, () -> String.format("Testing %s with exception at operation %d", description, throwAt));
        
        FileRecordStore store = filePath != null 
            ? createStoreWithExceptionAtPath(filePath, throwAt)
            : createStoreWithException(throwAt);
        
        ByteSequence key = ByteSequence.of("testkey".getBytes());
        byte[] data = "testdata".getBytes();
        
        try {
            store.insertRecord(key, data);
            Assert.fail("Expected IOException during " + description);
        } catch (IOException e) {
            logger.log(Level.FINE, () -> String.format("Got expected exception during %s: %s", description, e.getMessage()));
        }
        
        // Verify store is closed
        Assert.assertTrue("Store should be closed after " + description, store.isClosed());
        
        // Verify subsequent operations fail
        verifyStoreIsClosed(store);
        
        store.close();
    }

    /// Helper method for insert scenario with exception
    private void testInsertScenarioWithException(int throwAt, String description) throws Exception {
        logger.log(Level.FINE, () -> String.format("Testing insert scenario: %s with exception at operation %d", description, throwAt));
        
        // Pre-create store with some data to create realistic scenarios
        FileRecordStore prepStore = new FileRecordStore.Builder()
            .tempFile("insert-scenario-", ".db")
            .open();
        
        // Add some records to create free space and realistic conditions
        for (int i = 0; i < 5; i++) {
            ByteSequence key = ByteSequence.of(("existing" + i).getBytes());
            prepStore.insertRecord(key, ("existingdata" + i).getBytes());
        }
        
        // Delete some to create free space scenarios
        prepStore.deleteRecord(ByteSequence.of("existing1".getBytes()));
        prepStore.deleteRecord(ByteSequence.of("existing3".getBytes()));
        
        Path filePath = prepStore.getFilePath();
        prepStore.close();
        
        // Test insert with exception injection
        FileRecordStore testStore = createStoreWithExceptionAtPath(filePath, throwAt);
        ByteSequence newKey = ByteSequence.of("newkey".getBytes());
        byte[] newData = "newdata".getBytes();
        
        try {
            testStore.insertRecord(newKey, newData);
            Assert.fail("Expected IOException during " + description);
        } catch (IOException e) {
            logger.log(Level.FINE, () -> String.format("Insert failed as expected during %s: %s", description, e.getMessage()));
        }
        
        Assert.assertTrue("Store should be closed after " + description, testStore.isClosed());
        testStore.close();
    }

    /// Helper method for update scenario with exception
    private void testUpdateScenarioWithException(int throwAt, String description) throws Exception {
        logger.log(Level.FINE, () -> String.format("Testing update scenario: %s with exception at operation %d", description, throwAt));
        
        // Pre-create store with data
        FileRecordStore prepStore = new FileRecordStore.Builder()
            .tempFile("update-scenario-", ".db")
            .open();
        
        ByteSequence key = ByteSequence.of("updatekey".getBytes());
        prepStore.insertRecord(key, "originaldata".getBytes());
        Path filePath = prepStore.getFilePath();
        prepStore.close();
        
        // Test update with exception
        FileRecordStore testStore = createStoreWithExceptionAtPath(filePath, throwAt);
        byte[] newData = "updateddata".getBytes();
        
        try {
            testStore.updateRecord(key, newData);
            Assert.fail("Expected IOException during " + description);
        } catch (IOException e) {
            logger.log(Level.FINE, () -> String.format("Update failed as expected during %s: %s", description, e.getMessage()));
        }
        
        Assert.assertTrue("Store should be closed after " + description, testStore.isClosed());
        testStore.close();
    }

    /// Helper method for delete scenario with exception using behavior-based verification
    private void testDeleteScenarioWithException(int throwAt, String description) throws Exception {
        logger.log(Level.FINE, () -> String.format("Testing delete scenario: %s with exception at operation %d", description, throwAt));
        
        // Pre-create store with data
        FileRecordStore prepStore = new FileRecordStore.Builder()
            .tempFile("delete-scenario-", ".db")
            .open();
        
        ByteSequence key = ByteSequence.of("deletekey".getBytes());
        prepStore.insertRecord(key, "deletedata".getBytes());
        Path filePath = prepStore.getFilePath();
        prepStore.close();
        
        // Test delete with exception
        FileRecordStore testStore = createStoreWithExceptionAtPath(filePath, throwAt);
        DelegatingExceptionOperations exceptionOps = (DelegatingExceptionOperations) testStore.fileOperations;
        
        try {
            testStore.deleteRecord(key);
            
            // If we get here, exception wasn't triggered - that's fine for some operations
            logger.log(Level.FINE, () -> String.format("Operation %d not reached during %s - verifying store still works", throwAt, description));
            
            // Verify store is still operational
            Assert.assertFalse("Store should not be closed when no exception thrown", testStore.isClosed());
            Assert.assertFalse("Record should be deleted", testStore.recordExists(key));
            
        } catch (IOException e) {
            logger.log(Level.FINE, () -> String.format("Delete failed as expected during %s: %s", description, e.getMessage()));
            
            // Verify exception was actually thrown by our delegate
            Assert.assertTrue("Delegate should have thrown exception", exceptionOps.didThrow());
            Assert.assertEquals("Delegate should have reached target operation", throwAt, exceptionOps.getOperationCount());
            
            // Verify store is closed
            Assert.assertTrue("Store should be closed after " + description, testStore.isClosed());
            
            // Verify subsequent operations fail
            verifySubsequentOperationsFail(testStore);
        }
        
        testStore.close();
    }

    /// Helper method for read scenario with exception
    private void testReadScenarioWithException(int throwAt, String description, boolean disableCrc) throws Exception {
        logger.log(Level.FINE, () -> String.format("Testing read scenario: %s with exception at operation %d", description, throwAt));
        
        // Pre-create store with data and specific CRC setting
        FileRecordStore prepStore = new FileRecordStore.Builder()
            .tempFile("read-scenario-", ".db")
            .disablePayloadCrc32(disableCrc)
            .open();
        
        ByteSequence key = ByteSequence.of("readkey".getBytes());
        prepStore.insertRecord(key, "readdata".getBytes());
        Path filePath = prepStore.getFilePath();
        prepStore.close();
        
        // Test read with exception and same CRC setting
        FileRecordStore testStore = new FileRecordStore.Builder()
            .path(filePath)
            .disablePayloadCrc32(disableCrc)
            .open();
        
        // Replace file operations with exception injection
        RandomAccessFile raf = new RandomAccessFile(testStore.getFilePath().toFile(), "r");
        DirectRandomAccessFile directOps = new DirectRandomAccessFile(raf);
        DelegatingExceptionOperations exceptionOps = new DelegatingExceptionOperations(directOps, throwAt);
        testStore.fileOperations = exceptionOps;
        
        try {
            testStore.readRecordData(key);
            Assert.fail("Expected IOException during " + description);
        } catch (IOException e) {
            logger.log(Level.FINE, () -> String.format("Read failed as expected during %s: %s", description, e.getMessage()));
        }
        
        Assert.assertTrue("Store should be closed after " + description, testStore.isClosed());
        testStore.close();
    }

    /// Helper method for read non-existent scenario with exception
    private void testReadNonExistentWithException(int throwAt, String description) throws Exception {
        logger.log(Level.FINE, () -> String.format("Testing %s with exception at operation %d", description, throwAt));
        
        // Create empty store
        FileRecordStore testStore = createStoreWithException(throwAt);
        ByteSequence nonExistentKey = ByteSequence.of("nonexistent".getBytes());
        
        try {
            testStore.readRecordData(nonExistentKey);
            Assert.fail("Expected IOException during " + description);
        } catch (IOException e) {
            logger.log(Level.FINE, () -> String.format("Read non-existent failed as expected during %s: %s", description, e.getMessage()));
        }
        
        Assert.assertTrue("Store should be closed after " + description, testStore.isClosed());
        testStore.close();
    }

    /// Helper method for max key length scenario
    private void testMaxKeyLengthScenario(int throwAt) throws Exception {
        logger.log(Level.FINE, "Testing max key length scenario with exception at operation " + throwAt);
        
        // Create store with max key length
        FileRecordStore testStore = new FileRecordStore.Builder()
            .tempFile("maxkey-test-", ".db")
            .maxKeyLength(248) // Max theoretical key length
            .open();
        
        // Replace file operations with exception injection
        RandomAccessFile raf = new RandomAccessFile(testStore.getFilePath().toFile(), "rw");
        DirectRandomAccessFile directOps = new DirectRandomAccessFile(raf);
        DelegatingExceptionOperations exceptionOps = new DelegatingExceptionOperations(directOps, throwAt);
        testStore.fileOperations = exceptionOps;
        
        // Create max length key
        byte[] maxKeyBytes = new byte[248];
        for (int i = 0; i < 248; i++) {
            maxKeyBytes[i] = (byte) (i % 256);
        }
        ByteSequence maxKey = ByteSequence.of(maxKeyBytes);
        byte[] data = "maxkeydata".getBytes();
        
        try {
            testStore.insertRecord(maxKey, data);
            Assert.fail("Expected IOException during max key length operation");
        } catch (IOException e) {
            logger.log(Level.FINE, () -> String.format("Max key length operation failed as expected: %s", e.getMessage()));
        }
        
        Assert.assertTrue("Store should be closed after max key length exception", testStore.isClosed());
        testStore.close();
    }

    /// Helper method for empty data scenario
    private void testEmptyDataScenario(int throwAt) throws Exception {
        logger.log(Level.FINE, "Testing empty data scenario with exception at operation " + throwAt);
        
        FileRecordStore testStore = createStoreWithException(throwAt);
        ByteSequence key = ByteSequence.of("emptykey".getBytes());
        byte[] emptyData = new byte[0];
        
        try {
            testStore.insertRecord(key, emptyData);
            Assert.fail("Expected IOException during empty data operation");
        } catch (IOException e) {
            logger.log(Level.FINE, () -> String.format("Empty data operation failed as expected: %s", e.getMessage()));
        }
        
        Assert.assertTrue("Store should be closed after empty data exception", testStore.isClosed());
        testStore.close();
    }

    /// Helper method for fsync scenario with exception using behavior-based verification
    private void testFsyncScenarioWithException(int throwAt, String description) throws Exception {
        logger.log(Level.FINE, () -> String.format("Testing %s with exception at operation %d", description, throwAt));
        
        // Create store and add some data
        FileRecordStore prepStore = new FileRecordStore.Builder()
            .tempFile("fsync-scenario-", ".db")
            .open();
        
        ByteSequence key = ByteSequence.of("fsynckey".getBytes());
        prepStore.insertRecord(key, "fsyncdata".getBytes());
        Path filePath = prepStore.getFilePath();
        prepStore.close();
        
        // Test fsync with exception
        FileRecordStore testStore = createStoreWithExceptionAtPath(filePath, throwAt);
        DelegatingExceptionOperations exceptionOps = (DelegatingExceptionOperations) testStore.fileOperations;
        
        try {
            testStore.fsync();
            
            // If we get here, exception wasn't triggered - that's fine for some operations
            logger.log(Level.FINE, () -> String.format("Operation %d not reached during %s - verifying store still works", throwAt, description));
            
            // Verify store is still operational
            Assert.assertFalse("Store should not be closed when no exception thrown", testStore.isClosed());
            
        } catch (IOException e) {
            logger.log(Level.FINE, () -> String.format("Fsync failed as expected during %s: %s", description, e.getMessage()));
            
            // Verify exception was actually thrown by our delegate
            Assert.assertTrue("Delegate should have thrown exception", exceptionOps.didThrow());
            Assert.assertEquals("Delegate should have reached target operation", throwAt, exceptionOps.getOperationCount());
            
            // Verify store is closed
            Assert.assertTrue("Store should be closed after " + description, testStore.isClosed());
            
            // Verify subsequent operations fail
            verifySubsequentOperationsFail(testStore);
        }
        
        // Close the test store, handling potential exceptions during close
        try {
            testStore.close();
        } catch (IOException e) {
            logger.log(Level.FINE, () -> String.format("Exception during test cleanup close: %s", e.getMessage()));
            // This is expected if the exception was triggered during close operations
        }
    }
    
    /// Helper method to create a FileRecordStore with exception injection
    private FileRecordStore createStoreWithException(int throwAtOperation) throws IOException {
        logger.log(Level.FINE, () -> String.format("Creating store with exception at operation %d", throwAtOperation));
        
        // Create the base RandomAccessFile via builder temp file
        FileRecordStore baseStore = new FileRecordStore.Builder()
            .tempFile("exception-test-", ".db")
            .open();
        
        // Replace file operations with exception injection wrapper
        RandomAccessFile raf = new RandomAccessFile(baseStore.getFilePath().toFile(), "rw");
        DirectRandomAccessFile directOps = new DirectRandomAccessFile(raf);
        DelegatingExceptionOperations exceptionOps = new DelegatingExceptionOperations(directOps, throwAtOperation);
        
        // Create new store with exception wrapper
        FileRecordStore exceptionStore = new FileRecordStore.Builder()
            .path(baseStore.getFilePath())
            .open();
        
        // Replace the file operations with our exception wrapper
        exceptionStore.fileOperations = exceptionOps;
        
        // Close the base store since we're done with it
        baseStore.close();
        
        logger.log(Level.FINE, "Store created with exception injection wrapper");
        return exceptionStore;
    }
    
    /// Helper method to create a FileRecordStore with exception injection at specific path
    private FileRecordStore createStoreWithExceptionAtPath(Path filePath, int throwAtOperation) throws IOException {
        logger.log(Level.FINE, () -> String.format("Creating store with exception at operation %d for path %s", throwAtOperation, filePath));
        
        // Create store with the specified path
        FileRecordStore store = new FileRecordStore.Builder()
            .path(filePath)
            .open();
        
        // Replace file operations with exception injection wrapper
        RandomAccessFile raf = new RandomAccessFile(store.getFilePath().toFile(), "rw");
        DirectRandomAccessFile directOps = new DirectRandomAccessFile(raf);
        DelegatingExceptionOperations exceptionOps = new DelegatingExceptionOperations(directOps, throwAtOperation);
        
        // Replace the file operations with our exception wrapper
        store.fileOperations = exceptionOps;
        
        logger.log(Level.FINE, "Store created with exception injection wrapper at specified path");
        return store;
    }
    
    /// New behavior-based exception testing method
    private void testExceptionScenarioWithBehaviorVerification(int throwAt, String description) throws Exception {
        logger.log(Level.FINE, () -> String.format("Testing %s with exception at operation %d (behavior-based)", description, throwAt));
        
        FileRecordStore store = null;
        DelegatingExceptionOperations exceptionOps = null;
        
        try {
            store = createStoreWithException(throwAt);
            exceptionOps = (DelegatingExceptionOperations) store.fileOperations;
            
            ByteSequence key = ByteSequence.of("testkey".getBytes());
            byte[] data = "testdata".getBytes();
            
            try {
                store.insertRecord(key, data);
                
                // If no exception, verify store is still operational
                byte[] readData = store.readRecordData(key);
                Assert.assertArrayEquals("Data should be intact when no exception thrown", data, readData);
                logger.log(Level.FINE, () -> String.format("No exception at operation %d - store operational", throwAt));
                
            } catch (IOException e) {
                // Exception occurred as expected
                logger.log(Level.FINE, () -> String.format("Got expected exception at operation %d: %s", throwAt, e.getMessage()));
                
                // Verify exception was actually thrown by our delegate
                Assert.assertTrue("Delegate should have thrown exception", exceptionOps.didThrow());
                Assert.assertEquals("Delegate should have reached target operation", throwAt, exceptionOps.getOperationCount());
                
                // Verify subsequent operations fail appropriately
                verifySubsequentOperationsFail(store);
            }
            
        } finally {
            if (store != null) {
                try {
                    store.close();
                } catch (Exception e) {
                    // Ignore close exceptions in test cleanup
                }
            }
        }
    }

    /// Helper method to verify all public methods throw IllegalStateException
    private void verifyStoreIsClosed(FileRecordStore store) {
        ByteSequence key = ByteSequence.of("testkey".getBytes());
        byte[] data = "testdata".getBytes();
        
        // Test insertRecord
        try {
            store.insertRecord(key, data);
            Assert.fail("insertRecord should throw IllegalStateException when store is closed");
        } catch (IllegalStateException e) {
            logger.log(Level.FINE, "insertRecord correctly threw IllegalStateException: " + e.getMessage());
        } catch (IOException e) {
            Assert.fail("insertRecord should throw IllegalStateException, not IOException: " + e.getMessage());
        }
        
        // Test updateRecord
        try {
            store.updateRecord(key, data);
            Assert.fail("updateRecord should throw IllegalStateException when store is closed");
        } catch (IllegalStateException e) {
            logger.log(Level.FINE, "updateRecord correctly threw IllegalStateException: " + e.getMessage());
        } catch (IOException e) {
            Assert.fail("updateRecord should throw IllegalStateException, not IOException: " + e.getMessage());
        }
        
        // Test readRecordData
        try {
            store.readRecordData(key);
            Assert.fail("readRecordData should throw IllegalStateException when store is closed");
        } catch (IllegalStateException e) {
            logger.log(Level.FINE, "readRecordData correctly threw IllegalStateException: " + e.getMessage());
        } catch (IOException e) {
            Assert.fail("readRecordData should throw IllegalStateException, not IOException: " + e.getMessage());
        }
        
        // Test deleteRecord
        try {
            store.deleteRecord(key);
            Assert.fail("deleteRecord should throw IllegalStateException when store is closed");
        } catch (IllegalStateException e) {
            logger.log(Level.FINE, "deleteRecord correctly threw IllegalStateException: " + e.getMessage());
        } catch (IOException e) {
            Assert.fail("deleteRecord should throw IllegalStateException, not IOException: " + e.getMessage());
        }
        
        // Test keys()
        try {
            store.keys();
            Assert.fail("keys() should throw IllegalStateException when store is closed");
        } catch (IllegalStateException e) {
            logger.log(Level.FINE, "keys() correctly threw IllegalStateException: " + e.getMessage());
        } catch (Exception e) {
            Assert.fail("keys() should throw IllegalStateException, got: " + e.getClass().getSimpleName() + ": " + e.getMessage());
        }
        
        // Test isEmpty()
        try {
            store.isEmpty();
            Assert.fail("isEmpty() should throw IllegalStateException when store is closed");
        } catch (IllegalStateException e) {
            logger.log(Level.FINE, "isEmpty() correctly threw IllegalStateException: " + e.getMessage());
        } catch (Exception e) {
            Assert.fail("isEmpty() should throw IllegalStateException, got: " + e.getClass().getSimpleName() + ": " + e.getMessage());
        }
        
        // Test recordExists()
        try {
            store.recordExists(key);
            Assert.fail("recordExists() should throw IllegalStateException when store is closed");
        } catch (IllegalStateException e) {
            logger.log(Level.FINE, "recordExists() correctly threw IllegalStateException: " + e.getMessage());
        } catch (Exception e) {
            Assert.fail("recordExists() should throw IllegalStateException, got: " + e.getClass().getSimpleName() + ": " + e.getMessage());
        }
        
        // Test fsync()
        try {
            store.fsync();
            Assert.fail("fsync() should throw IllegalStateException when store is closed");
        } catch (IllegalStateException e) {
            logger.log(Level.FINE, "fsync() correctly threw IllegalStateException: " + e.getMessage());
        } catch (IOException e) {
            Assert.fail("fsync() should throw IllegalStateException, not IOException: " + e.getMessage());
        }
    }
    
    /// Helper to verify subsequent operations fail with IllegalStateException after exception
    private void verifySubsequentOperationsFail(FileRecordStore store) {
        ByteSequence key = ByteSequence.of("testkey".getBytes());
        byte[] data = "testdata".getBytes();
        
        // All operations should now throw IllegalStateException
        assertOperationFails(() -> {
            try {
                store.insertRecord(key, data);
            } catch (IOException e) {
                throw new RuntimeException(e);
            }
        }, "insertRecord");
        
        assertOperationFails(() -> {
            try {
                store.readRecordData(key);
            } catch (IOException e) {
                throw new RuntimeException(e);
            }
        }, "readRecordData");
        
        assertOperationFails(() -> {
            try {
                store.updateRecord(key, data);
            } catch (IOException e) {
                throw new RuntimeException(e);
            }
        }, "updateRecord");
        
        assertOperationFails(() -> {
            try {
                store.deleteRecord(key);
            } catch (IOException e) {
                throw new RuntimeException(e);
            }
        }, "deleteRecord");
        
        assertOperationFails(() -> store.keys(), "keys");
        assertOperationFails(() -> store.isEmpty(), "isEmpty");
        assertOperationFails(() -> store.recordExists(key), "recordExists");
        assertOperationFails(() -> {
            try {
                store.fsync();
            } catch (IOException e) {
                throw new RuntimeException(e);
            }
        }, "fsync");
    }
    
    /// Helper to assert that an operation fails with IllegalStateException
    private void assertOperationFails(Runnable operation, String operationName) {
        try {
            operation.run();
            Assert.fail(operationName + " should throw IllegalStateException");
        } catch (IllegalStateException e) {
            logger.log(Level.FINEST, () -> operationName + " correctly threw IllegalStateException: " + e.getMessage());
        } catch (RuntimeException e) {
            if (e.getCause() instanceof IOException) {
                Assert.fail(operationName + " should throw IllegalStateException, not IOException: " + e.getCause().getMessage());
            } else {
                throw e;
            }
        }
    }
    
    /// Verifies store integrity after writes and exceptions.
    ///
    /// @param store               the FileRecordStore to check
    /// @param expectedRecordCount expected number of records
    /// @param expectedValues      optional map of expected key->expected string data;
    ///                            if null, only non-empty checks are applied
    /// @param description         label for error messages
    private void verifyStoreIntegrity(
            FileRecordStore store,
            int expectedRecordCount,
            Map<ByteSequence, String> expectedValues,
            String description) {
    
        try {
            if (store.isClosed()) {
                throw new AssertionError(description + ": Store is closed, cannot verify integrity");
            }
    
            Iterable<ByteSequence> keys = store.keys();
            int actualCount = 0;
            for (ByteSequence key : keys) {
                actualCount++;
            }
    
            if (actualCount != expectedRecordCount) {
                throw new AssertionError(String.format(
                    "%s: Expected %d records but found %d",
                    description, expectedRecordCount, actualCount));
            }
    
            for (ByteSequence key : keys) {
                byte[] data;
                try {
                    data = store.readRecordData(key);
                } catch (IOException e) {
                    throw new AssertionError(description +
                        ": Failed to read data for key " + key.toBase64() + ": " + e.getMessage(), e);
                }
    
                if (data == null) {
                    throw new AssertionError(description +
                        ": Null data for key " + key.toBase64());
                }
    
                if (data.length == 0) {
                    throw new AssertionError(description +
                        ": Empty data for key " + key.toBase64());
                }
    
                if (expectedValues != null) {
                    String actual = new String(data, StandardCharsets.UTF_8);
                    String expected = expectedValues.get(key);
                    if (expected == null) {
                        throw new AssertionError(description +
                            ": Unexpected key found " + key.toBase64());
                    }
                    if (!expected.equals(actual)) {
                        throw new AssertionError(String.format(
                            "%s: Data mismatch for key %s - expected '%s' but got '%s'",
                            description, key.toBase64(), expected, actual));
                    }
                }
            }
    
            final int finalActualCount = actualCount;
            logger.log(Level.FINE,
                () -> String.format("%s: Verified %d records successfully",
                                    description, finalActualCount));
    
        } catch (AssertionError ae) {
            throw ae;
        } catch (Exception e) {
            throw new AssertionError(description +
                ": Unexpected error during verification: " + e.getMessage(), e);
        }
    }
    
    /// Test persistence verification after exceptions with controlled write sequence
    @Test
    public void testPersistenceVerificationAfterExceptions() throws Exception {
        logger.log(Level.FINE, "=== Testing persistence verification after exceptions ===");
        
        // Discover total operations for simple insert
        int totalOperations = discoverOperationCount();
        logger.log(Level.FINE, () -> String.format("Discovered %d operations for simple insert", totalOperations));
        
        // Test a few representative operations that should demonstrate persistence
        int[] testOperations = {1, Math.min(3, totalOperations), Math.min(5, totalOperations)};
        
        for (int throwAt : testOperations) {
            if (throwAt > totalOperations) continue;
            
            final int finalThrowAt = throwAt;
            logger.log(Level.FINE, () -> String.format("Testing persistence with exception at operation %d/%d", finalThrowAt, totalOperations));
            
            // Create store with exception injection
            FileRecordStore store = null;
            Path storePath = null;
            int successfulWrites = 0;
            Map<ByteSequence, String> expectedData = new HashMap<>();
            
            try {
                // Create base store first to get a path
                FileRecordStore baseStore = new FileRecordStore.Builder()
                    .tempFile("persistence-test-", ".db")
                    .open();
                storePath = baseStore.getFilePath();
                baseStore.close();
                
                // Now create store with exception injection at the same path
                store = createStoreWithExceptionAtPath(storePath, finalThrowAt);
                
                // Write multiple records sequentially
                for (int i = 0; i < 10; i++) {  // Try to write 10 records
                    final int recordIndex = i;
                    ByteSequence key = ByteSequence.of(("key_" + i).getBytes());
                    String data = "data_" + i;
                    
                    try {
                        store.insertRecord(key, data.getBytes(StandardCharsets.UTF_8));
                        successfulWrites++;
                        expectedData.put(key, data);
                        logger.log(Level.FINER, () -> String.format("Successfully wrote record %d", recordIndex));
                    } catch (IOException e) {
                        final int finalSuccessfulWrites = successfulWrites;
                        logger.log(Level.FINE, () -> String.format("Exception thrown at operation %d after %d successful writes", finalThrowAt, finalSuccessfulWrites));
                        break; // Stop writing after exception
                    }
                }
                
                // Verify store is now closed due to exception
                Assert.assertTrue("Store should be closed after exception", store.isClosed());
                
            } catch (Exception e) {
                logger.log(Level.FINE, () -> String.format("Exception during test setup or writing: %s", e.getMessage()));
            } finally {
                // Clean up the store
                if (store != null) {
                    try {
                        store.close();
                    } catch (Exception e) {
                        // Ignore close exceptions
                    }
                }
            }
            
            // Now verify persistence by opening a fresh store
            final int finalSuccessfulWrites = successfulWrites;
            final Path finalStorePath = storePath;
            final Map<ByteSequence, String> finalExpectedData = expectedData;
            
            if (finalStorePath != null && finalSuccessfulWrites > 0) {
                logger.log(Level.FINE, () -> String.format("Verifying persistence: reopening store with %d expected records", finalSuccessfulWrites));
                
                FileRecordStore freshStore = null;
                try {
                    freshStore = new FileRecordStore.Builder()
                        .path(finalStorePath)
                        .open();
                    
                    // Use our hybrid validation helper
                    final String verificationDescription = String.format("Persistence check after exception at operation %d", finalThrowAt);
                    verifyStoreIntegrity(freshStore, finalSuccessfulWrites, finalExpectedData, verificationDescription);
                    
                    logger.log(Level.FINE, () -> String.format("Persistence verified: %d records correctly stored", finalSuccessfulWrites));
                    
                } catch (Exception e) {
                    logger.log(Level.SEVERE, () -> String.format("Persistence verification failed: %s", e.getMessage()));
                    throw new AssertionError("Persistence verification failed: " + e.getMessage(), e);
                } finally {
                    if (freshStore != null) {
                        try {
                            freshStore.close();
                        } catch (Exception e) {
                            // Ignore close exceptions
                        }
                    }
                }
            } else if (finalStorePath != null) {
                logger.log(Level.FINE, () -> String.format("No successful writes to verify for operation %d", finalThrowAt));
            }
        }
        
        logger.log(Level.FINE, "=== Persistence verification testing completed ===");
    }
}